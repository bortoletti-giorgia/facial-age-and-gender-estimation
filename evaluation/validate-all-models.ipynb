{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd34e071",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c797489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT EXPERIMENTS DATA\n",
    "results_folder = os.getcwd()\n",
    "csv_details = \"EXPERIMENTS.csv\"\n",
    "\n",
    "exp_details = pd.read_csv(results_folder+\"/\"+csv_details)\n",
    "\n",
    "content = os.listdir(results_folder)\n",
    "exp_dirs = [d for d in content if os.path.isdir(d)][1:]\n",
    "exp_dirs = sorted(exp_dirs, key=lambda x: int(x.split(\"_\")[0]))\n",
    "\n",
    "folder_plots = \"plots/delta/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520723eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELS\n",
    "root = \"C:/0_thesis/3_experiment/\"\n",
    "models_rgb = []\n",
    "models_rgb.append(os.path.join(root, \"models/rgb_no_alpha/model_4\"))\n",
    "models_rgb.append(os.path.join(root, \"models/rgb_alpha05/model_4\"))\n",
    "models_rgb.append(os.path.join(root, \"models/rgb_alpha1/model_4\"))\n",
    "\n",
    "models_gray = []\n",
    "models_gray.append(os.path.join(root, \"models/gray_no_alpha/model_4\"))\n",
    "models_gray.append(os.path.join(root, \"models/gray_alpha05/model_4\"))\n",
    "models_gray.append(os.path.join(root, \"models/gray_alpha1/model_4\"))\n",
    "\n",
    "models = models_rgb + models_gray\n",
    "models_names = []\n",
    "for model_path in models:\n",
    "    models_names.append(model_path.split(\"/\")[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff40cae",
   "metadata": {},
   "source": [
    "# PREDICT ON ALL MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75bb0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model_path, images_path, colormode):\n",
    "    # Load model\n",
    "    model = keras.models.load_model(model_path)\n",
    "\n",
    "    # Predict on each image\n",
    "    img_size = 256\n",
    "    filenames = os.listdir(images_path)\n",
    "\n",
    "    ages = []\n",
    "    genders = []\n",
    "\n",
    "    for filename in filenames:\n",
    "        if colormode in filename:\n",
    "            filepath = images_path+\"/\"+filename\n",
    "        \n",
    "            img = tf.keras.utils.load_img(filepath, target_size = (img_size, img_size), color_mode=colormode)\n",
    "            img = tf.keras.utils.img_to_array(img)\n",
    "            img = img * (1./255)\n",
    "            img = tf.expand_dims(img, axis = 0)\n",
    "            prediction = model.predict(img)\n",
    "            prediction = np.round(prediction)\n",
    "            age_pred = int(prediction[0])\n",
    "            ages.append(age_pred)\n",
    "            gender_pred = \"male\" if prediction[1] == 0 else \"female\"\n",
    "            genders.append(gender_pred)\n",
    "\n",
    "    # Analysis\n",
    "    age_avg = sum(ages)/len(ages)\n",
    "    #print(\"Max age: \", max(ages))\n",
    "    #print(\"Min age: \", min(ages))\n",
    "    #print(\"Average: \", age_avg)\n",
    "    #print(\"Most gender: \", max(set(genders), key=genders.count))\n",
    "\n",
    "    final_age = np.round(age_avg)\n",
    "    final_gender = max(set(genders), key=genders.count)\n",
    "\n",
    "    return final_age, final_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868abf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATAFRAMES: 1 WITH PREDICTED AGE, 1 WITH PREDICTED GENDER \n",
    "df_age = pd.DataFrame(exp_dirs, columns = ['DIRNAME'] )\n",
    "df_age['ID'] = exp_details['ID']\n",
    "df_age['BEHAVIOR'] = exp_details['BEHAVIOR']\n",
    "df_age['AGE'] = exp_details['AGE']\n",
    "\n",
    "\n",
    "df_gender = pd.DataFrame(exp_dirs, columns = ['DIRNAME'] )\n",
    "df_gender['ID'] = exp_details['ID']\n",
    "df_gender['BEHAVIOR'] = exp_details['BEHAVIOR']\n",
    "df_gender['GENDER'] = exp_details['GENDER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef66177f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICT AND SAVE IN DATAFRAMES\n",
    "for experiment in exp_dirs:\n",
    "    print(\"EXPERIMENT: \", experiment)\n",
    "    images_path = results_folder+\"/\"+experiment+\"/photos/\"\n",
    "    row = df_age[df_age['DIRNAME'] == experiment].index\n",
    "    \n",
    "    for model_path in models_rgb:\n",
    "        age, gender = predict(model_path, images_path, colormode=\"rgb\")\n",
    "        model = model_path.split(\"/\")[-2]\n",
    "        df_age.loc[row, model] = age\n",
    "        df_gender.loc[row, model] = gender\n",
    "\n",
    "    for model_path in models_gray:\n",
    "        age, gender = predict(model_path, images_path, colormode=\"grayscale\")\n",
    "        model = model_path.split(\"/\")[-2]\n",
    "        df_age.loc[row, model] = age\n",
    "        df_gender.loc[row, model] = gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6354af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age.to_csv(\"age_prediction.csv\", index=False)\n",
    "df_gender.to_csv(\"gender_prediction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817504a7",
   "metadata": {},
   "source": [
    "## BALANCED MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c100f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "temp_root = \"C:/0_thesis/2_model/TESTING/BALANCE/\"\n",
    "models_rgb = []\n",
    "models_rgb.append(os.path.join(temp_root, \"19fold/model_4\"))\n",
    "models_rgb.append(os.path.join(temp_root, \"20netto/model_4\"))\n",
    "models_rgb.append(os.path.join(temp_root, \"20pepper05/model_4\"))\n",
    "models_gray = []\n",
    "models_gray.append(os.path.join(temp_root, \"19foldgray/model_4\"))\n",
    "models_gray.append(os.path.join(temp_root, \"20nettogray/model_4\"))\n",
    "models_gray.append(os.path.join(temp_root, \"20pepper05gray/model_4\"))\n",
    "\n",
    "# DATAFRAMES: 1 WITH PREDICTED AGE, 1 WITH PREDICTED GENDER \n",
    "df_balance_age = pd.DataFrame(exp_dirs, columns = ['DIRNAME'] )\n",
    "df_balance_age['ID'] = exp_details['ID']\n",
    "df_balance_age['BEHAVIOR'] = exp_details['BEHAVIOR']\n",
    "df_balance_age['AGE'] = exp_details['AGE']\n",
    "\n",
    "df_balance_gender = pd.DataFrame(exp_dirs, columns = ['DIRNAME'] )\n",
    "df_balance_gender['ID'] = exp_details['ID']\n",
    "df_balance_gender['BEHAVIOR'] = exp_details['BEHAVIOR']\n",
    "df_balance_gender['GENDER'] = exp_details['GENDER']\n",
    "\n",
    "# PREDICT AND SAVE IN DATAFRAMES\n",
    "for experiment in exp_dirs:\n",
    "    print(\"EXPERIMENT: \", experiment)\n",
    "    images_path = results_folder+\"/\"+experiment+\"/photos/\"\n",
    "    row = df_balance_age[df_balance_age['DIRNAME'] == experiment].index\n",
    "    \n",
    "    for model_path in models_rgb:\n",
    "        age, gender = predict(model_path, images_path, colormode=\"rgb\")\n",
    "        model = model_path.split(\"/\")[-2]\n",
    "        df_balance_age.loc[row, model] = age\n",
    "        df_balance_gender.loc[row, model] = gender\n",
    "\n",
    "    for model_path in models_gray:\n",
    "        age, gender = predict(model_path, images_path, colormode=\"grayscale\")\n",
    "        model = model_path.split(\"/\")[-2]\n",
    "        df_balance_age.loc[row, model] = age\n",
    "        df_balance_gender.loc[row, model] = gender\n",
    "        \n",
    "df_balance_age.to_csv(\"balance_age_prediction.csv\", index=False)\n",
    "df_balance_gender.to_csv(\"belance_gender_prediction.csv\", index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364f3c7a",
   "metadata": {},
   "source": [
    "# ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a201532",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_ranges = {'experiment': [range(0, 18), range(18, 30), range(30, 40), range(40, 50), \n",
    "                             range(50, 60), range(60, 70), range(70, 117)],\n",
    "              'paper2019': [range(0, 16), range(16, 30), range(30, 50), range(50, 117)],\n",
    "              'generations': [range(0, 11), range(11, 27), range(27, 43), range(43, 59), range(59, 78), range(78, 95)],\n",
    "              'paper_bari': [range(0, 26), range(26, 41), range(41, 61), range(61, 120)]}\n",
    "\n",
    "def get_group_from_age(age, age_groups):\n",
    "    for i, r in enumerate(age_groups):\n",
    "        if age in r:\n",
    "            return i\n",
    "    return None\n",
    "\n",
    "def get_groups_from(ages):\n",
    "    age_groups = dict.fromkeys(age_ranges)\n",
    "    for group_name in age_ranges.keys():\n",
    "        age_groups[group_name] = []\n",
    "        for age in ages:\n",
    "            age_groups[group_name].append(get_group_from_age(age, age_ranges[group_name]))\n",
    "    return age_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddde6a8",
   "metadata": {},
   "source": [
    "## Accuracy, MAE, precision, recall, F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06380876",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age = pd.read_csv(\"age_prediction.csv\", index_col=0)\n",
    "df_gender = pd.read_csv(\"gender_prediction.csv\", index_col=0)\n",
    "#df_age = pd.read_csv(\"balance_age_prediction.csv\")\n",
    "#df_gender = pd.read_csv(\"belance_gender_prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc127e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACCURACY ON GENDER\n",
    "gender_mapper = {'male': 0, 'female': 1}\n",
    "df_gender = df_gender.replace({\"GENDER\": gender_mapper})\n",
    "\n",
    "print(\"ACCURACY -- GENDER\")\n",
    "\n",
    "models = models_rgb + models_gray\n",
    "\n",
    "for model_path in models:\n",
    "    model = model_path.split(\"/\")[-2]\n",
    "    df_gender = df_gender.replace({model: gender_mapper})\n",
    "    accuracy = accuracy_score(df_gender[\"GENDER\"], df_gender[model])\n",
    "    print(model+\": \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251c9ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true age groups\n",
    "age_groups = get_groups_from(df_age[\"AGE\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c4b0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ACCURACY -- AGE GROUP\")\n",
    "\n",
    "models = models_rgb + models_gray\n",
    "\n",
    "# for every model\n",
    "for model_path in models:\n",
    "    model = model_path.split(\"/\")[-2]\n",
    "    print(\"------\"+model+\"-------\")\n",
    "    # for every age_ranges\n",
    "    pred_age_groups = get_groups_from(df_age[model].tolist())\n",
    "    for group_name in age_ranges.keys():\n",
    "        accuracy = accuracy_score(age_groups[group_name], pred_age_groups[group_name])\n",
    "        print(group_name+\":\",np.round(accuracy,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de10069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "print(\"MAE -- AGE\")\n",
    "\n",
    "models = models_rgb + models_gray\n",
    "\n",
    "mae = []\n",
    "for model_path in models:\n",
    "    model = model_path.split(\"/\")[-2]\n",
    "    mae.append(mean_absolute_error(y_true=df_age[\"AGE\"].tolist(), y_pred=df_age[model].tolist()))\n",
    "    print(model+\": \", mae[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dc3f53",
   "metadata": {},
   "source": [
    "# Indexes of wrong predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c9a659",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_age_groups = get_groups_from(df_age[\"gray_no_alpha\"].tolist())['experiment']\n",
    "age_groups = get_groups_from(df_age[\"AGE\"].tolist())['experiment']\n",
    "genders = df_gender['GENDER'].tolist()\n",
    "pred_genders = df_gender[\"gray_no_alpha\"].tolist()\n",
    "tot_experiments = int(len(genders)/2)\n",
    "tot_predictions = tot_experiments*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f28440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "offset_youngest = {}\n",
    "offset_oldest = {}\n",
    "marker_size = 5\n",
    "color_line = \"gray\"\n",
    "\n",
    "for model in models_names:\n",
    "    diff_age = df_age[model] - df_age[\"AGE\"]\n",
    "    predictions = df_age['ID']\n",
    "    \n",
    "    offset_youngest[model] = min(diff_age)\n",
    "    offset_oldest[model] = max(diff_age)\n",
    "       \n",
    "    fig, ax = plt.subplots(1,1,figsize=(16, 12))\n",
    "    \n",
    "    # points with error between -5 and -2.5 or 2.5 and 5\n",
    "    plt.plot(predictions, diff_age, 'yo', markersize=marker_size)\n",
    "\n",
    "    # error less than -5 or more than 5: red points\n",
    "    plt.axhline(y = 5, color = color_line)\n",
    "    plt.axhline(y = -5, color = color_line)\n",
    "    diff_age_red = []\n",
    "    exps_red = []\n",
    "    for i in range(len(diff_age)):\n",
    "        if diff_age[i] < -5 or diff_age[i] > 5:\n",
    "            diff_age_red.append(diff_age[i])\n",
    "            exps_red.append(predictions[i])\n",
    "    plt.plot(exps_red, diff_age_red, 'ro', markersize=marker_size)\n",
    "\n",
    "    # error between -2.5 and 2.5: green points\n",
    "    plt.axhline(y = 2.5, color = color_line)\n",
    "    plt.axhline(y = -2.5, color = color_line)\n",
    "    diff_age_green = []\n",
    "    exps_green = []\n",
    "    for i in range(len(diff_age)):\n",
    "        if diff_age[i] > -2.5 and diff_age[i] < 2.5:\n",
    "            diff_age_green.append(diff_age[i])\n",
    "            exps_green.append(predictions[i])\n",
    "    plt.plot(exps_green, diff_age_green, 'go', markersize=marker_size)\n",
    "\n",
    "    plt.xticks(np.arange(min(exps), max(exps)+1, 1))\n",
    "    plt.yticks(np.arange(-45, 52.5, 2.5))\n",
    "    plt.grid(axis='x')\n",
    "    plt.xlabel('Subjects')\n",
    "    plt.ylabel('Years of difference between the predicted and the actual age')\n",
    "    plt.title(model)\n",
    "    plt.savefig(folder_plots+'/'+model+\".jpg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f63580",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models_names:\n",
    "    print(model,\"\\t\",offset_youngest[model],\"\\t\",offset_oldest[model])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbb9aac",
   "metadata": {},
   "source": [
    "## GODSPEED\n",
    "\n",
    "Explicit: true; false age-group/younger; false age-group/older or wrong gender\n",
    "\n",
    "Implicit: true; false age-group/younger; false age-group/older or wrong gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512e8265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLICIT\n",
    "id_true_pred = []\n",
    "id_younger_pred = []\n",
    "id_older_pred = [] # or wrong gender\n",
    "tot_experiments = len(age_groups)\n",
    "\n",
    "for i in range(tot_experiments):\n",
    "    if df_age.iloc[i].BEHAVIOR == 'explicit':\n",
    "        exp_id = df_age.iloc[i].ID\n",
    "        if genders[i] != pred_genders[i] or pred_age_groups[i] > age_groups[i]:\n",
    "            id_older_pred.append(exp_id)\n",
    "        elif pred_age_groups[i] < age_groups[i]:\n",
    "            id_younger_pred.append(exp_id)\n",
    "        else:\n",
    "            id_true_pred.append(exp_id)\n",
    "            \n",
    "print(\"All EXPLICIT experiments are considered: \", (len(id_older_pred)+len(id_younger_pred)+len(id_true_pred))==(tot_experiments/2))\n",
    "\n",
    "print(\"Id experiments with true predictions: \", id_true_pred)\n",
    "print(\"Id experiments with younger predictions: \", id_younger_pred)\n",
    "print(\"Id experiments with older predictions or wrong gender: \", id_older_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab64444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPLICIT\n",
    "id_true_pred = []\n",
    "id_younger_pred = []\n",
    "id_older_pred = [] # or wrong gender\n",
    "tot_experiments = len(age_groups)\n",
    "\n",
    "for i in range(tot_experiments):\n",
    "    if df_age.iloc[i].BEHAVIOR == 'implicit':\n",
    "        exp_id = df_age.iloc[i].ID\n",
    "        if genders[i] != pred_genders[i] or pred_age_groups[i] > age_groups[i]:\n",
    "            id_older_pred.append(exp_id)\n",
    "        elif pred_age_groups[i] < age_groups[i]:\n",
    "            id_younger_pred.append(exp_id)\n",
    "        else:\n",
    "            id_true_pred.append(exp_id)\n",
    "            \n",
    "print(\"All IMPLICIT experiments are considered: \", (len(id_older_pred)+len(id_younger_pred)+len(id_true_pred))==(tot_experiments/2))\n",
    "\n",
    "print(\"Id experiments with true predictions: \", id_true_pred)\n",
    "print(\"Id experiments with younger predictions: \", id_younger_pred)\n",
    "print(\"Id experiments with older predictions or wrong gender: \", id_older_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc25ae7",
   "metadata": {},
   "source": [
    "## TRUST\n",
    "\n",
    "Considering the order of submission of the types of questionnaires."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc337767",
   "metadata": {},
   "source": [
    "## E+I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec2c3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLICIT first behavior\n",
    "id_true_pred = []\n",
    "id_younger_pred = []\n",
    "id_older_pred = [] # or wrong gender\n",
    "tot_experiments = len(age_groups)\n",
    "\n",
    "for i in range(tot_experiments):\n",
    "    if '_1_e' in df_age.iloc[i].DIRNAME:\n",
    "        exp_id = df_age.iloc[i].ID\n",
    "        if genders[i] != pred_genders[i] or pred_age_groups[i] > age_groups[i]:\n",
    "            id_older_pred.append(exp_id)\n",
    "        elif pred_age_groups[i] < age_groups[i]:\n",
    "            id_younger_pred.append(exp_id)\n",
    "        else:\n",
    "            id_true_pred.append(exp_id)\n",
    "            \n",
    "print(\"Id experiments with true predictions: \", id_true_pred)\n",
    "print(\"Id experiments with younger predictions: \", id_younger_pred)\n",
    "print(\"Id experiments with older predictions or wrong gender: \", id_older_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ab75d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPLICIT second behavior\n",
    "id_true_pred_2 = []\n",
    "id_younger_pred_2 = []\n",
    "id_older_pred_2 = [] # or wrong gender\n",
    "tot_experiments = len(age_groups)\n",
    "\n",
    "for i in range(tot_experiments):\n",
    "    if '_2_i' in df_age.iloc[i].DIRNAME:\n",
    "        exp_id = df_age.iloc[i].ID\n",
    "        if genders[i] != pred_genders[i] or pred_age_groups[i] > age_groups[i]:\n",
    "            id_older_pred_2.append(exp_id)\n",
    "        elif pred_age_groups[i] < age_groups[i]:\n",
    "            id_younger_pred_2.append(exp_id)\n",
    "        else:\n",
    "            id_true_pred_2.append(exp_id)\n",
    "\n",
    "print(\"Id experiments with true predictions:\", id_true_pred_2)\n",
    "print(\"Id experiments with younger predictions:\", id_younger_pred_2)\n",
    "print(\"Id experiments with older predictions or wrong gender:\", id_older_pred_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6577c1a8",
   "metadata": {},
   "source": [
    "## I+E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7036200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPLICIT first behavior\n",
    "id_true_pred = []\n",
    "id_younger_pred = []\n",
    "id_older_pred = [] # or wrong gender\n",
    "tot_experiments = len(age_groups)\n",
    "\n",
    "for i in range(tot_experiments):\n",
    "    if '_1_i' in df_age.iloc[i].DIRNAME:\n",
    "        exp_id = df_age.iloc[i].ID\n",
    "        if genders[i] != pred_genders[i] or pred_age_groups[i] > age_groups[i]:\n",
    "            id_older_pred.append(exp_id)\n",
    "        elif pred_age_groups[i] < age_groups[i]:\n",
    "            id_younger_pred.append(exp_id)\n",
    "        else:\n",
    "            id_true_pred.append(exp_id)\n",
    "\n",
    "print(\"Id experiments with true predictions:\", id_true_pred)\n",
    "print(\"Id experiments with younger predictions:\", id_younger_pred)\n",
    "print(\"Id experiments with older predictions or wrong gender:\", id_older_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ca5e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLICIT second behavior\n",
    "id_true_pred_2 = []\n",
    "id_younger_pred_2 = []\n",
    "id_older_pred_2 = [] # or wrong gender\n",
    "tot_experiments = len(age_groups)\n",
    "\n",
    "for i in range(tot_experiments):\n",
    "    if '_2_e' in df_age.iloc[i].DIRNAME:\n",
    "        exp_id = df_age.iloc[i].ID\n",
    "        if genders[i] != pred_genders[i] or pred_age_groups[i] > age_groups[i]:\n",
    "            id_older_pred_2.append(exp_id)\n",
    "        elif pred_age_groups[i] < age_groups[i]:\n",
    "            id_younger_pred_2.append(exp_id)\n",
    "        else:\n",
    "            id_true_pred_2.append(exp_id)\n",
    "\n",
    "print(\"Id experiments with true predictions:\", id_true_pred_2)\n",
    "print(\"Id experiments with younger predictions:\", id_younger_pred_2)\n",
    "print(\"Id experiments with older predictions or wrong gender:\", id_older_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223bee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All IMPLICIT experiments are considered:\", (len(id_older_pred)+len(id_younger_pred)+len(id_true_pred)+len(id_older_pred_2)+len(id_younger_pred_2)+len(id_true_pred_2))==(tot_experiments/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1769825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All IMPLICIT experiments are considered:\", (len(id_older_pred)+len(id_younger_pred)+len(id_true_pred)+len(id_older_pred_2)+len(id_younger_pred_2)+len(id_true_pred_2))==(tot_experiments/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407c87be",
   "metadata": {},
   "source": [
    "## Prediction stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b17c960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where age group or gender was predicted wrong in the experiment session\n",
    "pred_age_groups = get_groups_from(df_age[\"gray_no_alpha\"].tolist())['experiment']\n",
    "age_groups = get_groups_from(df_age[\"AGE\"].tolist())['experiment']\n",
    "genders = df_gender['GENDER'].tolist()\n",
    "pred_genders = df_gender[\"gray_no_alpha\"].tolist()\n",
    "tot_experiments = int(len(genders)/2)\n",
    "tot_predictions = tot_experiments*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00639a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STABILITY OF ALL PREDICTIONS:\n",
    "# if predictions of the two parts are equals -> stable\n",
    "# not considering if predictions are true or wrong \n",
    "# so wrong-wrong is stable \n",
    "id_diff_pred_age = []\n",
    "id_diff_pred_gender = []\n",
    "id_diff_pred = []\n",
    "for i in range(0, len(age_groups)-1, 2):\n",
    "    if pred_genders[i] != pred_genders[i+1] or pred_age_groups[i] != pred_age_groups[i+1]:\n",
    "        id_diff_pred.append(df_gender.iloc[i].ID)\n",
    "        if pred_genders[i] != pred_genders[i+1]:\n",
    "            id_diff_pred_gender.append(df_gender.iloc[i].ID)\n",
    "        if pred_age_groups[i] != pred_age_groups[i+1]:\n",
    "            id_diff_pred_age.append(df_gender.iloc[i].ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252ca361",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of predictions different in the two parts of experiment:\", len(id_diff_pred), \"on\", tot_experiments)\n",
    "print(\"Number of AGE GROUP predictions different in the two parts of experiment:\", len(id_diff_pred_age), \"on\", tot_experiments)\n",
    "print(\"Number of GENDER predictions different in the two parts of experiment:\", len(id_diff_pred_gender), \"on\", tot_experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f1fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return array of indexes of wrong prediction in only one of the two parts\n",
    "def clear_id_wrong_pred(id_wrong_pred):\n",
    "    # get indexes repeated once + numbers of wrong prediction in the same id session\n",
    "    # = 1 if it was wrong in only one part, 2 if it was wrong in both \n",
    "    unique_id_wrong_pred, frequency = np.unique(id_wrong_pred, return_counts = True)\n",
    "\n",
    "    # keep only if it was wrong in one:\n",
    "    # this means that prediction was not stable\n",
    "    indices = np.where(frequency==2)\n",
    "    return np.delete(unique_id_wrong_pred, indices)\n",
    "\n",
    "\n",
    "# STABILITY OF WRONG PREDICTIONS\n",
    "# if predictions of the two parts are: wrong-wrong -> stable\n",
    "id_wrong_pred = []\n",
    "id_wrong_pred_gender = []\n",
    "id_wrong_pred_age = []\n",
    "\n",
    "# add index of wrong predictions\n",
    "for i in range(0, len(age_groups)-1):\n",
    "    # if first prediction is wrong\n",
    "    if genders[i] != pred_genders[i] or age_groups[i] != pred_age_groups[i]:\n",
    "        id_wrong_pred.append(df_gender.iloc[i].ID)\n",
    "        if genders[i] != pred_genders[i]:\n",
    "            id_wrong_pred_gender.append(df_gender.iloc[i].ID)\n",
    "        if age_groups[i] != pred_age_groups[i]:\n",
    "            id_wrong_pred_age.append(df_gender.iloc[i].ID)\n",
    "\n",
    "# keep index only if one of the two predictions is wrong\n",
    "# so the other is true and that experiment is not stable\n",
    "id_single_wrong_pred = clear_id_wrong_pred(id_wrong_pred)\n",
    "id_single_wrong_pred_age = clear_id_wrong_pred(id_wrong_pred_age)\n",
    "id_single_wrong_pred_gender = clear_id_wrong_pred(id_wrong_pred_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e00c222",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of predictions in which only one of the two is wrong:\", len(id_single_wrong_pred), \"on\", tot_experiments)\n",
    "print(\"Number of AGE GROUP predictions in which only one of the two is wrong:\", len(id_single_wrong_pred_age), \"on\", tot_experiments)\n",
    "print(\"Number of GENDER predictions in which only one of the two is wrong:\", len(id_single_wrong_pred_gender), \"on\", tot_experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fd41af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(id_diff_pred_age)\n",
    "print(id_single_wrong_pred_age)\n",
    "# EXP 2: real_age_group = 1, pred_age_group_1 = 2, pred_age_group_2 = 3\n",
    "# both wrong so not in id_wrong_pred_age\n",
    "# but different so in id_diff_pred_age "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba021dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"% of AGE GROUP predictions equals in the two parts of experiment:\", (1-np.round(len(id_diff_pred_age)/tot_experiments,2))*100)\n",
    "print(\"% of GENDER predictions equals in the two parts of experiment:\", (1-np.round(len(id_diff_pred_gender)/tot_experiments,2))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274a2bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
