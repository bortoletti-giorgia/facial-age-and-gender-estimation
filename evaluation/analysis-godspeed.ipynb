{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668c8ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mean\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2f23e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = os.getcwd()\n",
    "csv_details = \"EXPERIMENTS.csv\"\n",
    "csv_explicit = \"explicit.csv\"\n",
    "csv_implicit = \"implicit.csv\"\n",
    "csv_init = \"init.csv\"\n",
    "\n",
    "folder_plots = \"plots/godspeed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68cc9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_details = pd.read_csv(results_folder+\"/\"+csv_details)\n",
    "survey_explicit = pd.read_csv(results_folder+\"/\"+csv_explicit)\n",
    "survey_implicit = pd.read_csv(results_folder+\"/\"+csv_implicit)\n",
    "\n",
    "# Isolate columns that we want\n",
    "# In surveys, Godspeed is from column 27 (starting from 0).\n",
    "for i in range(27):\n",
    "    survey_implicit.drop(survey_implicit.columns[[0]], axis=1, inplace=True)\n",
    "    survey_explicit.drop(survey_explicit.columns[[0]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe2531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_explicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7ea010",
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = [\"Anthropomorphism\", \"Animacy\", \"Likeability\", \"Intelligence\", \"Safety\",\n",
    "           \"OVERALL\", \"SYSUSE\", \"INFOQUAL\", \"INTERQUAL\"]\n",
    "\n",
    "sections_upper = [section.lower().upper() for section in sections]\n",
    "\n",
    "sections_plot = [\"Anthropomorphism\", \"Animacy\", \"Likeability\", \"Perceived\\nIntelligence\", \"Perceived\\nSafety\",\n",
    "           \"Overall\", \"System\\nUsefulness\", \"Information\\nQuality\", \"Interface\\nQuality\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1557a11e",
   "metadata": {},
   "source": [
    "# CREATE GODSPEED CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81768f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_godspeed(df_survey, from_col, to_col):\n",
    "    mean_godspeed = []\n",
    "    for index in range(len(df_survey)):\n",
    "        all_values = df_survey.iloc[index].tolist()\n",
    "        godspeed_index = all_values[from_col:to_col] # 5, 6 or 3 items depending on section\n",
    "        #print(len(godspeed_index))\n",
    "        mean_godspeed.append(np.round(mean(godspeed_index), 2))\n",
    "    return mean_godspeed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bc8a0b",
   "metadata": {},
   "source": [
    "OTHER METRICS:\n",
    "\n",
    "OVERALL: Average responses to 1 - 19\n",
    "\n",
    "System Usefulness (SYSUSE): average responses to 1 - 8\n",
    "\n",
    "Information Quality (INFOQUAL): average responses to 9 - 15\n",
    "\n",
    "Interface Quality (INTERQUAL): average responses to 16 - 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de5f626",
   "metadata": {},
   "outputs": [],
   "source": [
    "godspeed_implicit = {}\n",
    "godspeed_explicit = {}\n",
    "# Anthropomorphism\n",
    "godspeed_implicit[\"anthropomorphism\"] = get_mean_godspeed(survey_implicit, 0, 5)\n",
    "godspeed_explicit[\"anthropomorphism\"] = get_mean_godspeed(survey_explicit, 0, 5)\n",
    "\n",
    "#Animacy\n",
    "godspeed_implicit[\"animacy\"] = get_mean_godspeed(survey_implicit, 5, 11)\n",
    "godspeed_explicit[\"animacy\"] = get_mean_godspeed(survey_explicit, 5, 11)\n",
    "\n",
    "#Likeability\n",
    "godspeed_implicit[\"likeability\"] = get_mean_godspeed(survey_implicit, 11, 16)\n",
    "godspeed_explicit[\"likeability\"] = get_mean_godspeed(survey_explicit, 11, 16)\n",
    "\n",
    "#Perceived intelligence\n",
    "godspeed_implicit[\"intelligence\"] = get_mean_godspeed(survey_implicit, 16, 21)\n",
    "godspeed_explicit[\"intelligence\"] = get_mean_godspeed(survey_explicit, 16, 21)\n",
    "\n",
    "#Perceived safety\n",
    "godspeed_implicit[\"safety\"] = get_mean_godspeed(survey_implicit, 21, 24)\n",
    "godspeed_explicit[\"safety\"] = get_mean_godspeed(survey_explicit, 21, 24)\n",
    "\n",
    "# OVERALL: Average responses to 1 - 19 [0-18]\n",
    "godspeed_implicit[\"overall\"] = get_mean_godspeed(survey_implicit, 0, 19)\n",
    "godspeed_explicit[\"overall\"] = get_mean_godspeed(survey_explicit, 0, 19)\n",
    "\n",
    "# System Usefulness (SYSUSE): average responses to 1 - 8 [0-7]\n",
    "godspeed_implicit[\"sysuse\"] = get_mean_godspeed(survey_implicit, 0, 8)\n",
    "godspeed_explicit[\"sysuse\"] = get_mean_godspeed(survey_explicit, 0, 8)\n",
    "\n",
    "# Information Quality (INFOQUAL): average responses to 9 - 15 [8-14]\n",
    "godspeed_implicit[\"infoqual\"] = get_mean_godspeed(survey_implicit, 8, 15)\n",
    "godspeed_explicit[\"infoqual\"] = get_mean_godspeed(survey_explicit, 8, 15)\n",
    "\n",
    "# Interface Quality (INTERQUAL): average responses to 16 - 18 [15-17]\n",
    "godspeed_implicit[\"interqual\"] = get_mean_godspeed(survey_implicit, 15, 18)\n",
    "godspeed_explicit[\"interqual\"] = get_mean_godspeed(survey_explicit, 15, 18)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d9a254",
   "metadata": {},
   "source": [
    "### If we want to consider the order of questionnaires submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020cfb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of first and second surveys (explicit, implicit)\n",
    "'''\n",
    "first_surveys = []\n",
    "second_surveys = []\n",
    "for index in np.unique(exp_details['ID']):\n",
    "    order_behaviors = exp_details[exp_details['ID'] == index]['BEHAVIOR'].tolist()\n",
    "    first_surveys.append(order_behaviors[0])\n",
    "    second_surveys.append(order_behaviors[1])\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(np.unique(exp_details['ID']), columns = ['ID'] )\n",
    "df['FIRST_SURVEY'] = first_surveys\n",
    "df['SECOND_SURVEY'] = second_surveys\n",
    "\n",
    "# ADD sections\n",
    "for section in sections:\n",
    "    first_values = []\n",
    "    second_values = []\n",
    "    for i in range(len(first_surveys)):\n",
    "        if first_surveys[i] == 'explicit' and second_surveys[i] == 'implicit':\n",
    "            first_values.append(godspeed_explicit[section][i])\n",
    "            second_values.append(godspeed_implicit[section][i])\n",
    "        elif first_surveys[i] == 'implicit' and second_surveys[i] == 'explicit':\n",
    "            first_values.append(godspeed_implicit[section][i])\n",
    "            second_values.append(godspeed_explicit[section][i])\n",
    "        else:\n",
    "            print(\"ERROR: in explicit or implicit trust sequence.\")\n",
    "    df['FIRST_'+section.upper()] = first_values\n",
    "    df['SECOND_'+section.upper()] = second_values\n",
    "    \n",
    "# Save csv\n",
    "#df.to_csv(\"results_godspeed.csv\", index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d4b9db",
   "metadata": {},
   "source": [
    "### If we want to consider only type of questionnaire referring to the behavior (explicit, implicit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b2e9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe\n",
    "df = pd.DataFrame(np.unique(exp_details['ID']), columns = ['ID'] )\n",
    "\n",
    "# ADD sections\n",
    "for section in sections:\n",
    "    section = section.lower()\n",
    "    df['E_'+section.upper()] = godspeed_explicit[section]\n",
    "    df['I_'+section.upper()] = godspeed_implicit[section]\n",
    "\n",
    "# Save csv\n",
    "df.to_csv(\"results_godspeed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8504b649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe\n",
    "index = 0\n",
    "\n",
    "df1 = pd.DataFrame(np.concatenate((np.unique(exp_details['ID']),np.unique(exp_details['ID']))), columns = ['ID'])\n",
    "section = sections_upper[index].lower()\n",
    "df1[\"values\"] = godspeed_explicit[section]+godspeed_implicit[section]\n",
    "df1[\"section\"] = [sections_plot[index] for i in range(2*len(godspeed_explicit[section]))]\n",
    "df1['Behavior'] = ['explicit' for i in range(len(godspeed_explicit[section]))]+['implicit' for i in range(len(godspeed_explicit[section]))]\n",
    "index += 1\n",
    "    \n",
    "while index < len(sections):\n",
    "    # ADD sections\n",
    "    df2 = pd.DataFrame(np.concatenate((np.unique(exp_details['ID']),np.unique(exp_details['ID']))), columns = ['ID'])\n",
    "    section = sections_upper[index].lower()\n",
    "    df2[\"values\"] = godspeed_explicit[section]+godspeed_implicit[section]\n",
    "    df2[\"section\"] = [sections[index] for i in range(2*len(godspeed_explicit[section]))]\n",
    "    df2['Behavior'] = ['explicit' for i in range(len(godspeed_explicit[section]))]+['implicit' for i in range(len(godspeed_explicit[section]))]\n",
    "    index += 1\n",
    "\n",
    "    df1 = pd.concat([df1, df2], axis=0)\n",
    "        \n",
    "# Save csv\n",
    "df1.to_csv(\"results_godspeed_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dc0f29",
   "metadata": {},
   "source": [
    "# ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6724819",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"results_godspeed.csv\")\n",
    "#df.drop(df[df['ID'] == 59].index, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eee30bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics = pd.DataFrame(sections, columns = ['SECTION'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae8c786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_statistics(df, indexes, behavior, title):\n",
    "    for section in sections:\n",
    "        if behavior == \"explicit\":\n",
    "            if indexes:\n",
    "                col = df['E_'+section.upper()][indexes].tolist()\n",
    "            else:\n",
    "                col = df['E_'+section.upper()].tolist()\n",
    "        else:\n",
    "            if indexes:\n",
    "                col = df['I_'+section.upper()][indexes].tolist()\n",
    "            else:\n",
    "                col = df['I_'+section.upper()].tolist()\n",
    "            \n",
    "        row = statistics[statistics['SECTION'] == section].index\n",
    "        statistics.loc[row, 'MEAN_'+title] = np.round(mean(col), 2)\n",
    "        statistics.loc[row, 'STD_'+title] = np.round(np.std(col), 2)\n",
    "\n",
    "        #statistic, pvalue = stats.kstest(col_1, col_2)\n",
    "        #statistics.loc[row, 'PVALUE'] = np.round(pvalue, 2)\n",
    "    \n",
    "\n",
    "color_true_pred = \"#2ca02c\"\n",
    "color_younger_pred = \"black\"\n",
    "color_older_pred = \"r\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fffc362",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_statistics(df, indexes=None, behavior=\"explicit\", title=\"EXPLICIT\")\n",
    "update_statistics(df, indexes=None, behavior=\"implicit\", title=\"IMPLICIT\")\n",
    "statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770c5717",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics[\"MEAN_EXPLICIT\"] - statistics[\"MEAN_IMPLICIT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75905612",
   "metadata": {},
   "source": [
    "### EXPLICIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf57d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerosity = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f35b5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_ascending = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c69e50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "id_true_pred = [0, 1, 4, 5, 6, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 23, 24, 25, 26, 28, 31, 33, 35, 36, 37, 40, 41, 42, 43, 44, 46, 47, 49, 50, 51, 54, 57]\n",
    "id_younger_pred = [29, 34, 39, 45, 48, 52, 53, 55, 56, 59, 60, 61]\n",
    "id_older_pred = [2, 3, 7, 12, 15, 21, 22, 27, 30, 32, 38, 58]\n",
    "\n",
    "update_statistics(df, id_true_pred, \"explicit\", \"TRUE\")\n",
    "update_statistics(df, id_younger_pred, \"explicit\", \"YOUNGER\")\n",
    "update_statistics(df, id_older_pred, \"explicit\", \"OLDER\")\n",
    "statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4871871",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerosity['E_true'] = len(id_true_pred)\n",
    "numerosity['E_younger'] = len(id_younger_pred)\n",
    "numerosity['E_older'] = len(id_older_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd913c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if order_ascending:\n",
    "    statistics.sort_values(\"MEAN_TRUE\", inplace=True)\n",
    "    x_values = statistics[\"SECTION\"]\n",
    "else:\n",
    "    x_values = sections_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181c8ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean of Godspeed sections based age group and gender prediction in the EXPLICIT case\n",
    "fig, ax = plt.subplots(1,1,figsize=(14, 5)) \n",
    "\n",
    "true = statistics[\"MEAN_TRUE\"].tolist()\n",
    "ax.plot(x_values, true, 'o--', color=color_true_pred, label=\"Correct age group and gender\") \n",
    "\n",
    "younger = statistics[\"MEAN_YOUNGER\"].tolist()\n",
    "ax.plot(x_values, younger, 'o--', color=color_younger_pred, label=\"Younger age group and correct gender\") \n",
    "\n",
    "older = statistics[\"MEAN_OLDER\"].tolist()\n",
    "ax.plot(x_values, older, 'o--', color=color_older_pred, label=\"Older age group or wrong gender\") \n",
    "\n",
    "plt.yticks(np.arange(0, 5.5, 0.5))\n",
    "plt.grid(axis='x')\n",
    "plt.ylabel('Mean')\n",
    "plt.legend(loc='lower left')\n",
    "plt.xlabel('Section')\n",
    "plt.title('Godspeed mean in explicit behavior')\n",
    "\n",
    "#plt.savefig(folder_plots+\"/explicit.jpg\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c32aa0",
   "metadata": {},
   "source": [
    "### IMPLICIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeda2d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics = pd.DataFrame(statistics[\"SECTION\"], columns = ['SECTION'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6f36ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_true_pred = [3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 19, 20, 23, 24, 25, 28, 30, 31, 33, 37, 38, 40, 41, 42, 43, 44, 46, 47, 50, 51, 54, 58, 60]\n",
    "id_younger_pred = [0, 18, 26, 29, 34, 36, 39, 45, 48, 52, 53, 55, 56, 59, 61]\n",
    "id_older_pred = [1, 2, 7, 11, 14, 21, 22, 27, 32, 35, 49, 57]\n",
    "\n",
    "update_statistics(df, id_true_pred, \"implicit\", \"TRUE\")\n",
    "update_statistics(df, id_younger_pred, \"implicit\", \"YOUNGER\")\n",
    "update_statistics(df, id_older_pred, \"implicit\", \"OLDER\")\n",
    "statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b73e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerosity['I_true'] = len(id_true_pred)\n",
    "numerosity['I_younger'] = len(id_younger_pred)\n",
    "numerosity['I_older'] = len(id_older_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013e77ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "if order_ascending:\n",
    "    x_values = statistics[\"SECTION\"]\n",
    "else:\n",
    "    x_values = sections_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d992feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(14, 5)) \n",
    "\n",
    "true = statistics[\"MEAN_TRUE\"].tolist()\n",
    "ax.plot(x_values, true, 'o--', color=color_true_pred, label=\"Correct age group and gender\") \n",
    "\n",
    "younger = statistics[\"MEAN_YOUNGER\"].tolist()\n",
    "ax.plot(x_values, younger, 'o--', color=color_younger_pred, label=\"Younger age group and correct gender\") \n",
    "\n",
    "older = statistics[\"MEAN_OLDER\"].tolist()\n",
    "ax.plot(x_values, older, 'o--', color=color_older_pred, label=\"Older age group or wrong gender\") \n",
    "\n",
    "\n",
    "plt.yticks(np.arange(0, 5.5, 0.5))\n",
    "plt.grid(axis='x')\n",
    "plt.ylabel('Mean')\n",
    "plt.legend(loc='lower left')\n",
    "plt.xlabel('Section')\n",
    "plt.title('Godspeed mean in implicit behavior')\n",
    "\n",
    "#plt.savefig(folder_plots+\"/implicit.jpg\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa2b56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Correct age group and\\ngender\", \"Younger age group and\\ncorrect gender\", \"Older age group or\\nwrong gender\"]\n",
    "values_explicit = list(numerosity.values())[0:3]\n",
    "values_implicit = list(numerosity.values())[3:6]\n",
    "  \n",
    "fig, ax = plt.subplots(1,1,figsize=(10, 5)) \n",
    "\n",
    "# Set position of bar on X axis\n",
    "barWidth = 0.25\n",
    "br1 = np.arange(len(values_explicit))\n",
    "br2 = [x + barWidth for x in br1]\n",
    "\n",
    "\n",
    "plt.bar(br1, values_explicit, width = barWidth, edgecolor ='grey', label ='Explicit')\n",
    "plt.bar(br2, values_implicit, width = barWidth, edgecolor ='grey', label ='Implicit')\n",
    "\n",
    "ax.set_axisbelow(True)\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.ylabel(\"Number of predictions\")\n",
    "plt.xticks([r + barWidth/2 for r in range(len(labels))], labels)\n",
    "plt.yticks(np.arange(0, 40, 2))\n",
    "plt.xlabel(\"Prediction outcome\")\n",
    "plt.title(\"Numerosity of prediction outcomes\")\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(folder_plots+\"/numerosity.jpg\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e061ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(list(numerosity.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f389d06c",
   "metadata": {},
   "source": [
    "# STATISTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e2b8e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"results_godspeed.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0574c72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics = pd.DataFrame(sections_upper, columns = ['SECTION'] )\n",
    "for section in sections_upper:\n",
    "    data_e = df[\"E_\"+section].tolist()\n",
    "    data_i = df[\"I_\"+section].tolist()\n",
    "    \n",
    "    statistics_e = []\n",
    "    statistics_i = []\n",
    "    pvalues_e = []\n",
    "    pvalues_i = []\n",
    "    k_statistics = []\n",
    "    k_pvalues = []\n",
    "    man_statistics = []\n",
    "    man_pvalues = []\n",
    "    # https://scikit-posthocs.readthedocs.io/en/latest/intro.html\n",
    "    # parametric or not\n",
    "    statistic_e, pvalue_e = stats.kstest(data_e, 'norm')\n",
    "    statistic_i, pvalue_i = stats.kstest(data_i, 'norm')\n",
    "    statistics_e.append(np.round(statistic_e, 2))\n",
    "    statistics_i.append(np.round(statistic_i, 2))\n",
    "    pvalues_e.append(pvalue_e)\n",
    "    pvalues_i.append(pvalue_i)\n",
    "\n",
    "    # test not parametric chosen = Kruskal \n",
    "    k_statistic, k_pvalue = stats.kruskal(df[\"E_\"+section].tolist(), df[\"I_\"+section].tolist())\n",
    "    k_statistics.append(np.round(k_statistic, 2))\n",
    "    k_pvalues.append(np.round(k_pvalue, 2))\n",
    "    # if pvalues is less than 0.05 -> groups are significantly different\n",
    "    \n",
    "    # mannwhitneyu -> more than 0.05 -> same distribution\n",
    "    man_statistic, man_pvalue = stats.mannwhitneyu(df[\"E_\"+section].tolist(), df[\"I_\"+section].tolist())\n",
    "    man_statistics.append(np.round(man_statistic, 2))\n",
    "    man_pvalues.append(np.round(man_pvalue, 2))\n",
    "\n",
    "    row = statistics[statistics['SECTION'] == section].index\n",
    "    statistics.loc[row, \"e_kstest_stat\"] = statistics_e\n",
    "    statistics.loc[row, \"i_kstest_stat\"] = statistics_i\n",
    "    statistics.loc[row, \"e_kstest_pvalue\"] = pvalues_e\n",
    "    statistics.loc[row, \"i_kstest_pvalue\"] = pvalues_i\n",
    "    statistics.loc[row, \"kruskal_stat\"] = k_statistics\n",
    "    statistics.loc[row, \"kruskal_pvalue\"] = k_pvalues\n",
    "    statistics.loc[row, \"man_stat\"] = man_statistics\n",
    "    statistics.loc[row, \"man_pvalue\"] = man_pvalues\n",
    "    \n",
    "statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0785813",
   "metadata": {},
   "source": [
    "Kolmogorov-Smirnov test less than 0.05-> the null hypothesis is rejected and there is sufficient evidence to say that the data does not come from a normal distribution (both explicit and implicit)\n",
    "\n",
    "Since the data are not parametrics -> Kruskal test to check if data groups are significantly different (if p-value < 0.05) -> not for all\n",
    "\n",
    "Finally, the distribution of data with Mannwhitneyu -> more than 0.05 -> same distribution -> yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97278f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from statannotations.Annotator import Annotator\n",
    "\n",
    "df = pd.read_csv(\"results_godspeed_2.csv\")\n",
    "\n",
    "#create boxplot by group\n",
    "fig, ax = plt.subplots(1,1,figsize=(14, 5)) \n",
    "\n",
    "ax = sns.boxplot(data=df, x=\"section\", y=\"values\", hue=\"Behavior\", flierprops={\"marker\": \"x\"})\n",
    "\n",
    "'''\n",
    "annotator = Annotator(ax=ax, data=df, x=\"section\", y=\"values\", hue=\"Behavior\", \n",
    "                    pairs=[((\"Anthropomorphism\", \"explicit\"), (\"Anthropomorphism\", \"implicit\")),\n",
    "((\"Animacy\", \"explicit\"), (\"Animacy\", \"implicit\")),\n",
    "((\"Likeability\", \"explicit\"), (\"Likeability\", \"implicit\")),\n",
    "((\"Intelligence\", \"explicit\"), (\"Intelligence\", \"implicit\")),\n",
    "((\"Safety\", \"explicit\"), (\"Safety\", \"implicit\")),\n",
    "((\"OVERALL\", \"explicit\"), (\"OVERALL\", \"implicit\")),\n",
    "((\"SYSUSE\", \"explicit\"), (\"SYSUSE\", \"implicit\")),\n",
    "((\"INFOQUAL\", \"explicit\"), (\"INFOQUAL\", \"implicit\")),\n",
    "((\"INTERQUAL\", \"explicit\"), (\"INTERQUAL\", \"implicit\"))], order=sections, hue_order=['explicit', 'implicit'])\n",
    "\n",
    "annotator.configure(test='Mann-Whitney', text_format='star', loc='inside', verbose=2)\n",
    "annotator.apply_and_annotate()\n",
    "'''\n",
    "\n",
    "ax.set_xticklabels(sections_plot)\n",
    "ax.set_axisbelow(True)\n",
    "plt.grid(axis='y')\n",
    "plt.yticks(np.arange(0, 5.5, 0.5))\n",
    "plt.ylabel(\"Scores\")\n",
    "plt.xlabel(\"Section\")\n",
    "plt.title(\"Distribution of Godspeed scores\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig(folder_plots+\"/boxplots.jpg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812a9aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
